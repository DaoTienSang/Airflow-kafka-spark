from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from kafka import KafkaProducer
from vnstock import Vnstock
import json
import pandas as pd
import numpy as np
import time

# Class gi√∫p x·ª≠ l√Ω numpy v√† pandas datatype trong json
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, pd.Timestamp):
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        return super(NpEncoder, self).default(obj)

def fetch_and_push_to_kafka():
    vnstock_instance = Vnstock()
    stock = vnstock_instance.stock(symbol='VN30', source='VCI')
    symbols_df = stock.listing.all_symbols()
    symbols = symbols_df['symbol'].tolist()
    price_board = stock.trading.price_board(symbols_list=symbols)

    if isinstance(price_board.columns, pd.MultiIndex):
        price_board.columns = ['_'.join(map(str, col)).strip() for col in price_board.columns.values]

    snapshot = {'time': datetime.now().isoformat()}
    for symbol in symbols:
        try:
            row = price_board[price_board['listing_symbol'] == symbol]
            snapshot[symbol] = row['match_match_price'].values[0] if not row.empty else None
        except Exception:
            snapshot[symbol] = None

    producer = KafkaProducer(
        bootstrap_servers='kafka:9092',
        value_serializer=lambda v: json.dumps(v, cls=NpEncoder).encode('utf-8')
    )

    # G·ª≠i d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka
    producer.send('stock-topic', snapshot)
    print("‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka topic `stock-topic`")
    
    # L·∫•y v√† g·ª≠i d·ªØ li·ªáu l·ªãch s·ª≠ v√†o Kafka
    # L·∫•y nhi·ªÅu m√£ c·ªï phi·∫øu h∆°n theo y√™u c·∫ßu
    sample_symbols = symbols[:100]  # L·∫•y 100 m√£ ƒë·∫ßu ti√™n
    
    for symbol in sample_symbols:
        try:
            print(f"üîÑ ƒêang l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}...")
            # L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ 2000 ƒë·∫øn hi·ªán t·∫°i
            historical_data = stock.quote.history(
                symbol=symbol,
                start='2020-01-01', 
                end=datetime.now().strftime('%Y-%m-%d'),
                interval='1D'
            )
            
            # L·∫•y gi√° hi·ªán t·∫°i c·ªßa c·ªï phi·∫øu
            current_price = snapshot.get(symbol)
            
            # Chuy·ªÉn th√†nh dictionary ƒë·ªÉ serialize - x·ª≠ l√Ω ƒë√∫ng ki·ªÉu d·ªØ li·ªáu
            if not historical_data.empty:
                # Convert DataFrame to dict with Python native types 
                records = []
                for _, row in historical_data.iterrows():
                    record = {}
                    for col, val in row.items():
                        if isinstance(val, (np.integer, np.int64, np.int32)): 
                            record[col] = int(val)
                        elif isinstance(val, (np.floating, np.float64, np.float32)):
                            record[col] = float(val)
                        elif isinstance(val, pd.Timestamp):
                            record[col] = val.strftime('%Y-%m-%d')
                        else:
                            record[col] = val
                    records.append(record)
                
                historical_dict = {
                    'symbol': symbol,
                    'current_price': current_price,
                    'historical_data': records
                }
                
                # G·ª≠i v√†o Kafka
                producer.send('stock-history-topic', historical_dict)
                print(f"‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} v√†o Kafka topic `stock-history-topic`")
                
                # Th√™m delay ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API - tƒÉng th·ªùi gian ch·ªù ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu m√£
                time.sleep(10)  # ch·ªù 10 gi√¢y gi·ªØa c√°c l·∫ßn g·ªçi API
            
        except Exception as e:
            print(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}: {str(e)}")
            # N·∫øu g·∫∑p l·ªói gi·ªõi h·∫°n API, ch·ªù th√™m ƒë·ªÉ tr√°nh b·ªã block
            if "qu√° nhi·ªÅu request" in str(e).lower():
                print("‚è± ƒêang ch·ªù 30 gi√¢y ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API...")
                time.sleep(30)
    
    producer.flush()
    print("‚úÖ Ho√†n th√†nh vi·ªác ƒë·∫©y d·ªØ li·ªáu v√†o Kafka")

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
    'start_date': datetime(2025, 4, 17),
}

with DAG(
    dag_id='fetch_stock_to_kafka',
    default_args=default_args,
    schedule_interval='*/10 * * * *',
    catchup=False,
    tags=['stock', 'vnstock', 'kafka'],
) as dag:

    task = PythonOperator(
        task_id='fetch_push_kafka',
        python_callable=fetch_and_push_to_kafka
    )
