from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from kafka import KafkaProducer
from vnstock import Vnstock
import json
import pandas as pd
import numpy as np
import time

# Class gi√∫p x·ª≠ l√Ω numpy v√† pandas datatype trong json
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, pd.Timestamp):
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        return super(NpEncoder, self).default(obj)

def fetch_and_push_to_kafka():
    vnstock_instance = Vnstock()
    stock = vnstock_instance.stock(symbol='VN30', source='VCI')
    symbols_df = stock.listing.all_symbols()
    symbols = symbols_df['symbol'].tolist()
    price_board = stock.trading.price_board(symbols_list=symbols)

    if isinstance(price_board.columns, pd.MultiIndex):
        price_board.columns = ['_'.join(map(str, col)).strip() for col in price_board.columns.values]

    snapshot = {'time': datetime.now().isoformat()}
    for symbol in symbols:
        try:
            row = price_board[price_board['listing_symbol'] == symbol]
            snapshot[symbol] = row['match_match_price'].values[0] if not row.empty else None
        except Exception:
            snapshot[symbol] = None

    producer = KafkaProducer(
        bootstrap_servers='kafka:9092',
        value_serializer=lambda v: json.dumps(v, cls=NpEncoder).encode('utf-8'),
        batch_size=16384,  # TƒÉng k√≠ch th∆∞·ªõc batch
        buffer_memory=67108864  # TƒÉng b·ªô ƒë·ªám l√™n 64MB
    )

    # G·ª≠i d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka
    producer.send('stock-topic', snapshot)
    print("‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka topic `stock-topic`")
    
    # L·∫•y v√† g·ª≠i d·ªØ li·ªáu l·ªãch s·ª≠ v√†o Kafka
    # L·∫•y nhi·ªÅu m√£ c·ªï phi·∫øu h∆°n theo y√™u c·∫ßu
    sample_symbols = symbols[:100]  # L·∫•y 100 m√£ ƒë·∫ßu ti√™n
    
    # Chia th√†nh c√°c batch nh·ªè h∆°n ƒë·ªÉ x·ª≠ l√Ω song song
    batch_size = 5  # X·ª≠ l√Ω m·ªói l·∫ßn 5 m√£
    symbol_batches = [sample_symbols[i:i+batch_size] for i in range(0, len(sample_symbols), batch_size)]
    
    for batch_idx, symbol_batch in enumerate(symbol_batches):
        print(f"üîÑ X·ª≠ l√Ω batch {batch_idx+1}/{len(symbol_batches)} v·ªõi {len(symbol_batch)} m√£...")
        
        for symbol in symbol_batch:
            try:
                print(f"üîÑ ƒêang l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}...")
                # L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ 2000 ƒë·∫øn hi·ªán t·∫°i
                historical_data = stock.quote.history(
                    symbol=symbol,
                    start='2020-01-01', 
                    end=datetime.now().strftime('%Y-%m-%d'),
                    interval='1D'
                )
                
                # L·∫•y gi√° hi·ªán t·∫°i c·ªßa c·ªï phi·∫øu
                current_price = snapshot.get(symbol)
                
                # Chuy·ªÉn th√†nh dictionary ƒë·ªÉ serialize - x·ª≠ l√Ω ƒë√∫ng ki·ªÉu d·ªØ li·ªáu
                if not historical_data.empty:
                    # Convert DataFrame to dict with Python native types 
                    records = []
                    for _, row in historical_data.iterrows():
                        record = {}
                        for col, val in row.items():
                            if isinstance(val, (np.integer, np.int64, np.int32)): 
                                record[col] = int(val)
                            elif isinstance(val, (np.floating, np.float64, np.float32)):
                                record[col] = float(val)
                            elif isinstance(val, pd.Timestamp):
                                record[col] = val.strftime('%Y-%m-%d')
                            else:
                                record[col] = val
                        records.append(record)
                    
                    historical_dict = {
                        'symbol': symbol,
                        'current_price': current_price,
                        'historical_data': records
                    }
                    
                    # G·ª≠i v√†o Kafka
                    producer.send('stock-history-topic', historical_dict)
                    print(f"‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} v√†o Kafka topic `stock-history-topic`")
                    
                    # Th√™m delay ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API - gi·∫£m th·ªùi gian ch·ªù
                    time.sleep(5)  # Gi·∫£m t·ª´ 10 xu·ªëng 5 gi√¢y
                
            except Exception as e:
                print(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}: {str(e)}")
                # N·∫øu g·∫∑p l·ªói gi·ªõi h·∫°n API, ch·ªù th√™m ƒë·ªÉ tr√°nh b·ªã block
                if "qu√° nhi·ªÅu request" in str(e).lower():
                    print("‚è± ƒêang ch·ªù 30 gi√¢y ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API...")
                    time.sleep(30)
        
        # Sau m·ªói batch, ch·ªù m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o API kh√¥ng b·ªã qu√° t·∫£i
        if batch_idx < len(symbol_batches) - 1:
            print(f"‚è± ƒê√£ x·ª≠ l√Ω xong batch {batch_idx+1}, ƒëang ch·ªù 15 gi√¢y tr∆∞·ªõc khi x·ª≠ l√Ω batch ti·∫øp theo...")
            time.sleep(15)
    
    producer.flush()
    print("‚úÖ Ho√†n th√†nh vi·ªác ƒë·∫©y d·ªØ li·ªáu v√†o Kafka")

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
    'start_date': datetime(2023, 5, 1),
}

with DAG(
    dag_id='fetch_stock_to_kafka',
    default_args=default_args,
    schedule_interval='*/30 * * * *',  # Th·ª±c hi·ªán m·ªói 30 ph√∫t thay v√¨ 10 ph√∫t
    catchup=False,
    tags=['stock', 'vnstock', 'kafka'],
) as dag:

    task = PythonOperator(
        task_id='fetch_push_kafka',
        python_callable=fetch_and_push_to_kafka
    )
